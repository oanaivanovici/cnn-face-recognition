{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN for Monkey Classification.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"ruFEgmZDTw13","colab_type":"text"},"cell_type":"markdown","source":["**Mount drive**\n","\n","Source: Mounting Google Drive: https://colab.research.google.com/notebooks/io.ipynb"]},{"metadata":{"id":"MYrMJI5UslQQ","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-1nhsOLD13EO","colab_type":"text"},"cell_type":"markdown","source":["**Imports**"]},{"metadata":{"id":"L92ZzAC910uo","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","import keras\n","import os\n","import numpy as np\n","\n","from keras.models import Model\n","from keras.optimizers import Adam, SGD, Adagrad, RMSprop\n","from keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, Flatten, Activation, BatchNormalization, ZeroPadding2D\n","from keras.layers import Concatenate\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.pooling import MaxPooling2D\n","from keras.utils import plot_model\n","from keras.callbacks import EarlyStopping\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.applications.inception_v3 import preprocess_input"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9v0y5iR6ON0O","colab_type":"text"},"cell_type":"markdown","source":["**Actual AlexNet**\n","\n","Sources:\n","\n","Caffe implementation: http://dandxy89.github.io/ImageModels/alexnet/\n","\n","Parameters and architecture: https://medium.com/@smallfishbigsea/a-walk-through-of-alexnet-6cbd137a5637\n","\n","Layers order, Activation and Batch Normalization: https://www.mydatahack.com/building-alexnet-with-keras/"]},{"metadata":{"id":"rzwxTqcNONVx","colab_type":"code","colab":{}},"cell_type":"code","source":["input_layer = Input(shape=(227, 227, 3))\n","\n","first_layer_1 = Conv2D(48, kernel_size=(11, 11), strides=(4,4), padding='same')(input_layer)\n","first_layer_1 = Activation('relu')(first_layer_1)\n","first_layer_1 = BatchNormalization()(first_layer_1)\n","first_layer_1 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(first_layer_1) \n","first_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(first_layer_1) \n","\n","second_layer_1 = Conv2D(128, kernel_size=(5, 5), strides=(3, 3), padding='same')(first_layer_1) \n","second_layer_1 = Activation('relu')(second_layer_1)\n","second_layer_1 = BatchNormalization()(second_layer_1)\n","second_layer_1 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(second_layer_1) \n","second_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(second_layer_1)\n","\n","third_layer_1 = Conv2D(192, kernel_size=(3,3), strides=(3, 3), padding='same')(second_layer_1) \n","third_layer_1 = Activation('relu')(third_layer_1)\n","third_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(third_layer_1)\n","\n","fourth_layer_1 = Conv2D(192, kernel_size=(3,3), strides=(3,3), padding='same')(third_layer_1)\n","fourth_layer_1 = Activation('relu')(fourth_layer_1)\n","fourth_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(fourth_layer_1)\n","\n","fifth_layer_1 = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(fourth_layer_1) # changed stride to 1\n","fifth_layer_1 = Activation('relu')(fifth_layer_1)\n","#fifth_layer_1 = BatchNormalization()(fifth_layer_1)\n","fifth_layer_1 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(fifth_layer_1)\n","fifth_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(fifth_layer_1)\n","\n","sixth_layer_1 = Flatten()(fifth_layer_1)\n","sixth_layer_1 = Dropout(0.5)(sixth_layer_1)\n","sixth_layer_1 = Dense(2048, input_shape=(227, 227, 3), activation='relu')(sixth_layer_1)\n","\n","seventh_layer_1 = Dropout(0.5)(sixth_layer_1)\n","seventh_layer_1 = Dense(2048, activation='relu')(seventh_layer_1)\n","\n","#eighth_layer = Dropout(0.5)(seventh_layer_1)\n","final_layer = Dense(34, activation='softmax')(seventh_layer_1)\n","\n","model = Model(inputs=input_layer, outputs=final_layer)\n","\n","# display model summary\n","print(model.summary())\n","\n","# plot model\n","plot_model(model, to_file='Actual_Original_AlexNet_plot.png', show_shapes=True, show_layer_names=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xRKR77iXe63Z","colab_type":"text"},"cell_type":"markdown","source":["**Further modifications of original AlexNet**\n","\n","Sources:\n","\n","Caffe implementation: http://dandxy89.github.io/ImageModels/alexnet/\n","\n","Parameters and architecture: https://medium.com/@smallfishbigsea/a-walk-through-of-alexnet-6cbd137a5637\n","\n","Layers order, Activation and Batch Normalization: https://www.mydatahack.com/building-alexnet-with-keras/"]},{"metadata":{"id":"zSYX9lOye42O","colab_type":"code","colab":{}},"cell_type":"code","source":["input_layer = Input(shape=(227, 227, 3))\n","\n","first_layer_1 = Conv2D(48, kernel_size=(11, 11), strides=(4,4), padding='same')(input_layer)\n","first_layer_1 = Activation('relu')(first_layer_1)\n","first_layer_1 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(first_layer_1) \n","first_layer_1 = BatchNormalization()(first_layer_1)\n","first_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(first_layer_1) \n","\n","second_layer_1 = Conv2D(128, kernel_size=(5, 5), strides=(3, 3), padding='same')(first_layer_1) \n","second_layer_1 = Activation('relu')(second_layer_1)\n","second_layer_1 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(second_layer_1) \n","second_layer_1 = BatchNormalization()(second_layer_1)\n","second_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(second_layer_1)\n","\n","third_layer_1 = Conv2D(192, kernel_size=(3,3), strides=(3, 3), padding='same')(second_layer_1) \n","third_layer_1 = Activation('relu')(third_layer_1)\n","third_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(third_layer_1)\n","\n","fourth_layer_1 = Conv2D(192, kernel_size=(3,3), strides=(3,3), padding='same')(third_layer_1)\n","fourth_layer_1 = Activation('relu')(fourth_layer_1)\n","fourth_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(fourth_layer_1)\n","\n","fifth_layer_1 = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(fourth_layer_1) # changed stride to 1\n","fifth_layer_1 = Activation('relu')(fifth_layer_1)\n","fifth_layer_1 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(fifth_layer_1)\n","#fifth_layer_1 = BatchNormalization()(fifth_layer_1)\n","fifth_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(fifth_layer_1)\n","\n","sixth_layer_1 = Flatten()(fifth_layer_1)\n","sixth_layer_1 = Dropout(0.5)(sixth_layer_1)\n","sixth_layer_1 = Dense(2048, input_shape=(227, 227, 3), activation='relu')(sixth_layer_1)\n","\n","seventh_layer_1 = Dropout(0.5)(sixth_layer_1)\n","seventh_layer_1 = Dense(2048, activation='relu')(seventh_layer_1)\n","\n","#eighth_layer = Dropout(0.5)(seventh_layer_1)\n","final_layer = Dense(34, activation='softmax')(seventh_layer_1)\n","\n","model = Model(inputs=input_layer, outputs=final_layer)\n","\n","# display model summary\n","print(model.summary())\n","\n","# plot model\n","plot_model(model, to_file='V3_Original_AlexNet_plot.png', show_shapes=True, show_layer_names=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Rvk3q8dfT1sN","colab_type":"text"},"cell_type":"markdown","source":["\n","\n","**Other variation of AlexNet**\n","\n","Resulting image calculation: 1 + [(original dimension + padding x 2 — filter dimension) / stride size] - as stated in https://mc.ai/classify-butterfly-images-with-deep-learning-in-keras/\n","\n","Sources: \n","\n","Caffe implementation: http://dandxy89.github.io/ImageModels/alexnet/\n","\n","Parameters and architecture: https://medium.com/@smallfishbigsea/a-walk-through-of-alexnet-6cbd137a5637 \n","\n","Layers order, Activation and Batch Normalization: https://www.mydatahack.com/building-alexnet-with-keras/\n","\n","Comments based on: A. Krizhevsky, I. Sutskever, and G. E. Hinton, “ImageNet Classification with Deep Convolutional Neural Networks,” in ImageNet Classification with Deep Convolutional Neural Networks, 2012.\n","\n"]},{"metadata":{"id":"ryeXkU--KChv","colab_type":"code","colab":{}},"cell_type":"code","source":["#The first convolutional layer filters the 224x224x3/227x227x3 input image \n","#with 96 kernels of size 11x11x3 with a stride of 4 pixels\n","input_layer = Input(shape=(227, 227, 3))\n","\n","initial_layer = Conv2D(3, kernel_size=(13, 13), strides=(1, 1), padding='same')(input_layer)\n","initial_layer = Activation('relu')(initial_layer)\n","initial_layer = MaxPooling2D(pool_size=(4,4), strides=(4,4))(initial_layer)\n","initial_layer = BatchNormalization()(initial_layer)\n","initial_layer = ZeroPadding2D(((1, 1), (1, 1)))(initial_layer)\n","\n","first_layer_1 = Conv2D(48, kernel_size=(11, 11), strides=(1,1), padding='same')(initial_layer) \n","first_layer_1 = Activation('relu')(first_layer_1)\n","first_layer_1 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(first_layer_1) \n","first_layer_1 = BatchNormalization()(first_layer_1)\n","\n","#The second convolutional layer takes as input the (response-normalized ReLu and pooled) output \n","#of the first convolutional layer, and filters it with 256 kernels of size 5 x 5 x 48\n","second_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(first_layer_1) \n","second_layer_1 = Conv2D(128, kernel_size=(5, 5), strides=(1, 1), padding='same')(second_layer_1) # changed from 256 to 128\n","second_layer_1 = Activation('relu')(second_layer_1)\n","second_layer_1 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(second_layer_1) \n","second_layer_1 = BatchNormalization()(second_layer_1)\n","\n","#The third convolutional layer has 384 kernels of size 3x3x256 connected to the \n","#(normalized, pooled) outputs of the second convolutional layer\n","third_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(second_layer_1)\n","third_layer_1 = Conv2D(192, kernel_size=(3,3), strides=(1, 1), padding='same')(third_layer_1) # changed from 384 to 192\n","third_layer_1 = Activation('relu')(third_layer_1)\n","\n","#The third, fourth, and fifth convolutional layers are connected to one another \n","#without any pooling or normalization layers.\n","\n","#The fourth convolutional layer has 384 kernels of size 3x3x192\n","fourth_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(third_layer_1)\n","fourth_layer_1 = Conv2D(192, kernel_size=(3,3), strides=(1,1), padding='same')(fourth_layer_1)\n","fourth_layer_1 = Activation('relu')(fourth_layer_1)\n","\n","#The fifth convolutional layer has 256 kernels of size 3x3x192 \n","fifth_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(fourth_layer_1)\n","fifth_layer_1 = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(fifth_layer_1) # changed 256 to 128\n","fifth_layer_1 = Activation('relu')(fifth_layer_1)\n","fifth_layer_1 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(fifth_layer_1)\n","fifth_layer_1 = BatchNormalization()(fifth_layer_1)\n","fifth_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(fifth_layer_1)\n","\n","#The 3 fully-connected layers have 4096 neurons each.\n","#We use dropout in the first two fully-connected layers.\n","#Flatten layers connect Convolutional layers and Dense layers\n","sixth_layer_1 = Flatten()(fifth_layer_1)\n","sixth_layer_1 = Dropout(0.5)(sixth_layer_1)\n","sixth_layer_1 = Dense(2048, input_shape=(227, 227, 3), activation='relu')(sixth_layer_1) #changed 4096 to 2048\n","\n","seventh_layer_1 = Dropout(0.5)(sixth_layer_1)\n","seventh_layer_1 = Dense(2048, activation='relu')(seventh_layer_1)\n","\n","added_layer = Dropout(0.5)(seventh_layer_1)\n","added_layer = Dense(1024, activation='relu')(added_layer)\n","\n","eighth_layer = Dropout(0.5)(added_layer)\n","\n","final_layer = Dense(34, activation='softmax')(eighth_layer)\n","\n","model = Model(inputs=input_layer, outputs=final_layer)\n","\n","# display model summary\n","print(model.summary())\n","\n","# plot model\n","plot_model(model, to_file='PLOT_CNN, AlexNet V3, 75 epochs, ImgAug.png', show_shapes=True, show_layer_names=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Wfdgwrur180V","colab_type":"text"},"cell_type":"markdown","source":["**Other variation of CNN**"]},{"metadata":{"id":"itFWs9gH18Ia","colab_type":"code","colab":{}},"cell_type":"code","source":["input_layer = Input(shape=(227, 227, 3))\n","\n","initial_layer = Conv2D(3, kernel_size=(11, 11), strides=(1, 1), padding='same')(input_layer)\n","initial_layer = MaxPooling2D(pool_size=(3,3), strides=(2,2))(initial_layer)\n","initial_layer = Activation('relu')(initial_layer)\n","initial_layer = BatchNormalization()(initial_layer)\n","\n","added_layer = ZeroPadding2D(((1, 1), (1, 1)))(initial_layer)\n","added_layer = Conv2D(32, kernel_size=(11, 11), strides=(4,4), padding='same')(added_layer)\n","added_layer = MaxPooling2D(pool_size=(3,3), strides=(2,2))(added_layer)\n","added_layer = Activation('relu')(added_layer)\n","added_layer = BatchNormalization()(added_layer)\n","\n","first_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(added_layer)\n","first_layer_1 = Conv2D(48, kernel_size=(11, 11), strides=(4,4), padding='same')(first_layer_1) # changed from 96 to 48\n","first_layer_1 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(first_layer_1) \n","first_layer_1 = Activation('relu')(first_layer_1)\n","first_layer_1 = BatchNormalization()(first_layer_1)\n","\n","added_layer_2 = ZeroPadding2D(((1, 1), (1, 1)))(first_layer_1)\n","added_layer_2 = Conv2D(64, kernel_size=(7, 7), strides=(1,1), padding='same')(added_layer_2)\n","added_layer_2 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(added_layer_2)\n","added_layer_2 = Activation('relu')(added_layer_2)\n","added_layer_2 = BatchNormalization()(added_layer_2)\n","\n","second_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(added_layer_2) \n","second_layer_1 = Conv2D(128, kernel_size=(5, 5), strides=(1, 1), padding='same')(second_layer_1) # changed from 256 to 128\n","second_layer_1 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(second_layer_1) \n","second_layer_1 = Activation('relu')(second_layer_1)\n","second_layer_1 = BatchNormalization()(second_layer_1)\n","\n","third_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(second_layer_1)\n","third_layer_1 = Conv2D(192, kernel_size=(3,3), strides=(1, 1), padding='same')(third_layer_1) # changed from 384 to 192\n","third_layer_1 = Activation('relu')(third_layer_1)\n","\n","fourth_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(third_layer_1)\n","fourth_layer_1 = Conv2D(192, kernel_size=(3,3), strides=(1,1), padding='same')(fourth_layer_1)\n","fourth_layer_1 = Activation('relu')(fourth_layer_1)\n","\n","fifth_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(fourth_layer_1)\n","fifth_layer_1 = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(fifth_layer_1) # changed 256 to 128\n","fifth_layer_1 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(fifth_layer_1)\n","fifth_layer_1 = Activation('relu')(fifth_layer_1)\n","fifth_layer_1 = BatchNormalization()(fifth_layer_1)\n","\n","sixth_layer_1 = ZeroPadding2D(((1, 1), (1, 1)))(fifth_layer_1)\n","sixth_layer_1 = Flatten()(sixth_layer_1)\n","sixth_layer_1 = Dropout(0.5)(sixth_layer_1)\n","sixth_layer_1 = Dense(2048, input_shape=(227, 227, 3), activation='relu')(sixth_layer_1)\n","\n","seventh_layer_1 = Dropout(0.5)(sixth_layer_1)\n","seventh_layer_1 = Dense(2048, activation='relu')(seventh_layer_1)\n","\n","eighth_layer = Dropout(0.5)(seventh_layer_1)\n","\n","final_layer = Dense(34, activation='softmax')(eighth_layer)\n","\n","model = Model(inputs=input_layer, outputs=final_layer)\n","\n","print(model.summary())\n","\n","plot_model(model, to_file='CNN_model_7_plot.png', show_shapes=True, show_layer_names=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KDG6mk8sfwA3","colab_type":"text"},"cell_type":"markdown","source":["**Load new model from h5 file, if neccesary**"]},{"metadata":{"id":"Xymb2xYMeAry","colab_type":"code","colab":{}},"cell_type":"code","source":["model_path = 'drive/My Drive/Colab Notebooks/Trained Models /Transfer learning/InceptionV3, fully trained, SGD optimizer, 50 epochs, ImgAug.h5'\n","new_model = keras.models.load_model(model_path)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"933yWquT2wIz","colab_type":"text"},"cell_type":"markdown","source":["**Compile and Train Model**\n","\n","Sources:\n","\n","Image Data Generator: https://keras.io/preprocessing/image/ , https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n","\n","Validation split and subsets: https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator/52372042#52372042\n","\n","Getting the class indeces: https://stackoverflow.com/questions/38971293/get-class-labels-from-keras-functional-model\n","\n","Generators, flow_from_directory, training the model: https://medium.com/@vijayabhaskar96/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\n","\n","EarlyStopping: https://keras.io/callbacks/#earlystopping "]},{"metadata":{"id":"IgiK4opA2sYp","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size_train_and_validation = 32\n","number_of_epochs = 75\n","image_target_size = (227, 227)\n","\n","# compile model\n","model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy', 'top_k_categorical_accuracy'])\n","#model.compile(SGD(lr=0.001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy', 'top_k_categorical_accuracy'])\n","\n","# data preprocessing & augumentation\n","train_datagenerator = ImageDataGenerator(preprocessing_function=preprocess_input,\n","                                         rescale=1./255,\n","                                         zoom_range=0.1,\n","                                         shear_range=0.2,\n","                                         width_shift_range=0.1,\n","                                         height_shift_range=0.1,\n","                                         rotation_range=20,                                         \n","                                         #width_shift_range=0.15,\n","                                         #height_shift_range=0.15,\n","                                         #brightness_range=(0.1, 0.2),\n","                                         #horizontal_flip=True,\n","                                         #rotation_range=45,\n","                                         #vertical_flip=True,\n","                                         validation_split=0.2)\n","\n","#directory_path = 'drive/My Drive/Monkey Faces/New Split/train'\n","directory_path = 'drive/My Drive/Good folder macaque images/train'\n","\n","train_generator=train_datagenerator.flow_from_directory(directory_path,\n","                                                        color_mode = 'rgb',\n","                                                        class_mode ='categorical',\n","                                                        batch_size = batch_size_train_and_validation,\n","                                                        shuffle = True,\n","                                                        target_size=image_target_size,\n","                                                        subset = 'training')\n","validation_generator=train_datagenerator.flow_from_directory(directory_path,\n","                                                             color_mode = 'rgb',\n","                                                             class_mode = 'categorical',\n","                                                             batch_size = batch_size_train_and_validation,\n","                                                             shuffle = True,\n","                                                             target_size=image_target_size,\n","                                                             subset = 'validation')\n","\n","#get the class for each monkey as an index from the flow_from_directory\n","label_map = (train_generator.class_indices) \n","print(label_map)\n","\n","# calculate the steps sizes for train and validation\n","step_size_train = train_generator.n//batch_size_train_and_validation\n","step_size_validation = validation_generator.n//batch_size_train_and_validation\n","print(step_size_train, step_size_validation)\n","\n","# earlystopping in case accuracy does not improve during training\n","early_stopping = EarlyStopping(monitor='val_loss',\n","                               min_delta=0.01,\n","                               patience=20,\n","                               mode='auto',\n","                               restore_best_weights=True)\n","\n","# train model\n","model_gen = model.fit_generator(generator = train_generator,\n","                    steps_per_epoch = step_size_train,\n","                    validation_data = validation_generator,\n","                    validation_steps = step_size_validation, \n","                    epochs = number_of_epochs,\n","                    callbacks=[early_stopping])\n","\n","#new_model.save('InceptionV3, fully trained, SGD optimizer, 50 epochs, ImgAug, last epoch.h5')\n","model.save('CNN_AlexNet_V0_Good Folder Only.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TfIuCJ54UzRM","colab_type":"text"},"cell_type":"markdown","source":["**Plot graph**\n","\n","Source: https://keras.io/visualization/"]},{"metadata":{"id":"rKsM7i5ScB4F","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.plot(model_gen.history['acc'])\n","plt.plot(model_gen.history['val_acc'])\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","plt.show()\n","\n","plt.plot(model_gen.history['loss'])\n","plt.plot(model_gen.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vCGOGoMXdZed","colab_type":"text"},"cell_type":"markdown","source":["**Create test generator, evaluate test generator and validation generator**\n","\n","Sources:\n","\n","Test data generator, test steps, validation steps: https://stackoverflow.com/questions/45806669/keras-how-to-use-predict-generator-with-imagedatagenerator"]},{"metadata":{"colab_type":"code","id":"NTXO8ihPipzG","colab":{}},"cell_type":"code","source":["image_target_size = (227, 227)\n","\n","test_directory_path = 'drive/My Drive/Monkey Faces/New Split/test (With subfolders)'\n","#test_directory_path = 'drive/My Drive/Good folder macaque images/test'\n","\n","test_datagenerator = ImageDataGenerator(preprocessing_function=preprocess_input,\n","                                        rescale=1./255)\n","\n","test_generator = test_datagenerator.flow_from_directory(test_directory_path,\n","                                                        color_mode = 'rgb',\n","                                                        class_mode ='categorical',\n","                                                        batch_size = 1,\n","                                                        shuffle = False,\n","                                                        target_size=image_target_size)\n","\n","test_steps = len(test_generator.filenames)\n","validation_steps = len(validation_generator.filenames)\n","\n","# evaluate validation generator\n","print(\"Validation evaluation:\")\n","validation_evaluation = model.evaluate_generator(validation_generator, validation_steps)\n","print(\"Loss: \", validation_evaluation[0], \", \", \"Top-1 Accuracy: \", validation_evaluation[1], \", \",\n","     \"Top-5 accuracy: \", validation_evaluation[2])\n","\n","# evaluate test generator\n","print(\"Test evaluation:\")\n","print(model.metrics_names)\n","test_evaluation = model.evaluate_generator(test_generator, steps = test_steps)\n","print(\"Loss: \", test_evaluation[0], \", \", \"Top-1 accuracy: \", test_evaluation[1], \", \", \n","      \"Top-5 accuracy: \", test_evaluation[2])\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9t4tS8CddpKi","colab_type":"text"},"cell_type":"markdown","source":["**Make predictions with model**\n","\n","Source:\n","\n","predict_generator: https://stackoverflow.com/questions/45806669/keras-how-to-use-predict-generator-with-imagedatagenerator"]},{"metadata":{"id":"VKQ8xgVdQLfj","colab_type":"code","colab":{}},"cell_type":"code","source":["test_generator.reset()\n","\n","predictions = model.predict_generator(test_generator, steps = test_steps)\n","\n","# index for iterating through file names produced by generator, to print out the monkey\n","# because shuffle=False, the train_generator will take the files using next() and therefore\n","# in the order printed by the monkey_names\n","monkey_index = 0\n","\n","for individual_prediction in predictions:\n","  print(test_generator.filenames[monkey_index].partition('/')[0])\n","  #print(individual_prediction)\n","  predictions_descending = (-individual_prediction).argsort()\n","  #print(predictions_descending)\n","  top_5_predictions = predictions_descending[:5]\n","  #print(top_5_predictions)\n","\n","  top_5_monkeys = {}\n","  for monkey_name, id_in_map in label_map.items():\n","    # find the monkeys from label_map which are in top 5\n","    if (id_in_map in top_5_predictions): \n","      # cast top 5 monkeys to a dictionary\n","      top_5_monkeys[monkey_name, id_in_map] = individual_prediction[id_in_map]\n","      \n","  for monkey in sorted(top_5_monkeys, key=top_5_monkeys.get, reverse=True):\n","    print(monkey, top_5_monkeys[monkey])\n","\n","  monkey_index += 1  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"7cY1g9TWYhdN","colab_type":"text"},"cell_type":"markdown","source":["**Plot confusion matrix**\n","\n","Source:\n","\n","Confusion matrix: https://groups.google.com/forum/#!topic/keras-users/bqWwFox_zZs , https://www.kaggle.com/amarjeet007/visualize-cnn-with-keras"]},{"metadata":{"id":"E5vtDUv9X8uR","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# plot confusion matrix\n","classes = test_generator.classes[test_generator.index_array]\n","top_prediction = np.argmax(predictions, axis=-1)\n","conf_matrix = confusion_matrix(test_generator.classes[test_generator.index_array], top_prediction)\n","\n","plt.figure(figsize=(15,15))\n","sns.heatmap(conf_matrix, annot=True, fmt=\"d\")"],"execution_count":0,"outputs":[]}]}